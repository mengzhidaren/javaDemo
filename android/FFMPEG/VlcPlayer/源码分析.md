######流媒体的音视频同步：https://www.cnblogs.com/jiayayao/p/6890882.html
```
  vlc播放流媒体时实现音视频同步，简单来说就是发送方发送的RTP包带有时间戳，接收方根据此时间戳不断校正本地时钟，
  播放音视频时根据本地时钟进行同步播放。首先了解两个概念：stream clock和system clock。stream clock是流时钟，
  可以理解为RTP包中的时间戳；system clock是本地时钟，可以理解为当前系统的Tick数
第一个RTP包到来时：

fSyncTimestamp = rtpTimestamp;// rtp时间戳赋值为本地记录的时间戳
fSyncTime = timeNow;// 本地同步时钟直接赋值为本地当前时钟，注意这样赋值是错误的，但随后就会被RTCP的SR包修正

之后有RTP包到来，则根据上一次RTP包的时间戳差值计算得到真实的时间差值：

// Divide this by the timestamp frequency to get real time:
double timeDiff = timestampDiff/(double)timestampFrequency;// 差值除以90KHz得到真实时间

    当RTCP的Sender Report（SR）包到来时，会对fSyncTime进行重置，直接赋值为NTP时间戳

fSyncTime.tv_sec = ntpTimestampMSW - 0x83AA7E80; // 1/1/1900 -> 1/1/1970
double microseconds = (ntpTimestampLSW*15625.0)/0x04000000; // 10^6/2^32
fSyncTime.tv_usec = (unsigned)(microseconds+0.5);
    然后以此差值更新fSyncTime，也就是说live555接收部分的时钟fSyncTime既由RTP包时间戳不断的校正，也由RTCP的SR包不断的赋值修改。

    在RTSP的Session建立时会创建解码器的本地时钟，本地时钟是一对时钟，包括stream clock和system clock，初始值均为INVALID。


....

同理，音频解码完后，也会进行stream clock到system clock的转换。音频的解码后的数据会直接播放，
视频解码完的图像帧会放入图像fifo(src\misc\picture_fifo.c)中，等待渲染线程渲染。渲染线程会根据解码后图像的显示时间，决定是否播放：


整个接收流程的框图如下， 可以看出两个解码线程其实并没有直接联系，它们之间的联系是通过音视频数据包的的stream clock转换为system clock，
然后渲染线程和声音播放线程根据本地时钟决定是否要播放当前音视频数据。
```


























